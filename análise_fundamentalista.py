# -*- coding: utf-8 -*-
"""Análise Fundamentalista.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YU6tcb5t0M6Frl8SNmV0asZcVc1l4u6h

# Análise Exploratória dos fundamentos de empresas listadas em bolsa seguindo o método de Greenbland, Grahan com algumas personalizações
"""

import pandas as pd
import numpy as np
import requests
import functools
import os
from sqlalchemy import create_engine
from dotenv import load_dotenv

load_dotenv()

url = "https://statusinvest.com.br/category/advancedsearchresult?search=%7B%22Sector%22%3A%22%22%2C%22SubSector%22%3A%22%22%2C%22Segment%22%3A%22%22%2C%22my_range%22%3A%220%3B25%22%2C%22dy%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22p_L%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22peg_Ratio%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22p_VP%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22p_Ativo%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22margemBruta%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22margemEbit%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22margemLiquida%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22p_Ebit%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22eV_Ebit%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22dividaLiquidaEbit%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22dividaliquidaPatrimonioLiquido%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22p_SR%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22p_CapitalGiro%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22p_AtivoCirculante%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22roe%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22roic%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22roa%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22liquidezCorrente%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22pl_Ativo%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22passivo_Ativo%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22giroAtivos%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22receitas_Cagr5%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22lucros_Cagr5%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22liquidezMediaDiaria%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22vpa%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22lpa%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%2C%22valorMercado%22%3A%7B%22Item1%22%3Anull%2C%22Item2%22%3Anull%7D%7D&CategoryType=1"
json = requests.get(url).json()
base_de_dados = pd.DataFrame(json)
base_de_dados.fillna(0, inplace=True)
base_de_dados.head(5)

# obter minima e máxima
url = "https://statusinvest.com.br/acao/getaltabaixa?IndiceCode=&Filter="
json = requests.get(url).json()
base_complementar = pd.DataFrame(json)
base_complementar.fillna(0, inplace=True)
base_complementar.index = base_complementar['code']
base_complementar.head(5)

"""## Ajustando index das linhas igual ao ticker



"""

base_de_dados.index =  base_de_dados['ticker']
base_de_dados.head(5)

"""## Adicionando Dados complementares de preço minimo e máximo do dia"""

min_max = base_complementar.loc[:, ['minValue', 'maxValue']]
min_max[min_max['minValue'] == 0] = "0,00"
min_max[min_max['maxValue'] == 0] = "0,00"
min_max = min_max.apply(lambda x: x.str.replace('.',''))
min_max = min_max.apply(lambda x: x.str.replace(',','.'))
min_max = min_max.apply(lambda x: x.str.replace('--','0.0'))

min_max['minValue'] = min_max['minValue'].astype(float)
min_max['maxValue'] = min_max['maxValue'].astype(float)

base_de_dados = pd.concat([base_de_dados, min_max], axis=1)

# Removendo ativos sem vriação de preço
base_de_dados.loc[base_de_dados['minValue'] == base_de_dados['maxValue'], ['minValue', 'maxValue']] = 0.0

# calculando queda máxima
base_de_dados['queda_max'] = 0
base_de_dados.loc[(base_de_dados['maxValue'] > 0) & (base_de_dados['maxValue'] != base_de_dados['price']), 'queda_max'] = (base_de_dados['price'] / base_de_dados['maxValue'] - 1) * 100

base_de_dados.head(5)

"""## Criando rankings

### EV/EBIT
"""

ranking_ev_ebit = base_de_dados.loc[:, ['eV_Ebit']]
ranking_ev_ebit.loc[ranking_ev_ebit['eV_Ebit'] < 0.2, ['eV_Ebit']] = 1000 # tratando valroes negativos

ranking_ev_ebit['rank'] = ranking_ev_ebit['eV_Ebit'].rank(ascending=False)
ranking_ev_ebit.sort_values(by='rank', ascending=False, inplace=True)

ranking_ev_ebit.head(10)

"""### ROIC

"""

ranking_roic = base_de_dados.loc[:, ['roic']]
ranking_roic['rank'] = ranking_roic['roic'].rank(ascending=True)
ranking_roic.sort_values(by='rank', ascending=False, inplace=True)
ranking_roic.head(10)

"""### CAGR (Lucros 5 anos)"""

ranking_cagr = base_de_dados.loc[:, ['lucros_Cagr5']]
ranking_cagr = ranking_cagr[ranking_cagr['lucros_Cagr5'] > 0] # Filtrar somente CAGR positivo
ranking_cagr['rank'] = ranking_cagr['lucros_Cagr5'].rank(ascending=True)
ranking_cagr.sort_values(by='rank', ascending=False, inplace=True)
ranking_cagr.head(10)

"""### Queda Máxima"""

ranking_queda_max = base_de_dados.loc[:, ['queda_max', 'price', 'maxValue']]
ranking_queda_max['rank'] = ranking_queda_max['queda_max'].rank(ascending=False)
ranking_queda_max.sort_values(by='rank', ascending=False, inplace=True)
ranking_queda_max.head(10)

"""### P/L"""

ranking_pl = base_de_dados.loc[:, ['p_L']]
ranking_pl = ranking_pl[ranking_pl['p_L'] > 0]
ranking_pl['rank'] = ranking_pl['p_L'].rank(ascending=False)
ranking_pl.sort_values(by='rank', ascending=False, inplace=True)
ranking_pl.head(10)

"""### P/VP

"""

ranking_pvp = base_de_dados.loc[:, ['p_VP']]
ranking_pvp = ranking_pvp[ranking_pvp['p_VP'] > 0]
ranking_pvp['rank'] = ranking_pvp['p_VP'].rank(ascending=False)
ranking_pvp.sort_values(by='rank', ascending=False, inplace=True)
ranking_pvp.head(10)

"""### Div. Líquida / Patrimônio"""

ranking_dvlp = base_de_dados.loc[:, ['dividaliquidaPatrimonioLiquido']]
ranking_dvlp['rank'] = ranking_dvlp['dividaliquidaPatrimonioLiquido'].rank(ascending=False)
ranking_dvlp.sort_values(by='rank', ascending=False, inplace=True)
ranking_dvlp.head(10)

"""### Liquidez Corrente"""

ranking_liqcorrente = base_de_dados.loc[:, ['liquidezCorrente']]
ranking_liqcorrente = ranking_liqcorrente[ranking_liqcorrente['liquidezCorrente'] > 0]
ranking_liqcorrente['rank'] = ranking_liqcorrente['liquidezCorrente'].rank(ascending=True)
ranking_liqcorrente.sort_values(by='rank', ascending=False, inplace=True)
ranking_liqcorrente.head(10)

"""### ROE"""

ranking_roe = base_de_dados.loc[:, ['roe']]
ranking_roe['rank'] = ranking_roe['roe'].rank(ascending=True)
ranking_roe.sort_values(by='rank', ascending=False, inplace=True)
ranking_roe.head(10)

"""### Dividend Yield"""

ranking_dy = base_de_dados.loc[:, ['dy']]
ranking_dy = ranking_dy[ranking_dy['dy'] > 0]
ranking_dy['rank'] = ranking_dy['dy'].rank(ascending=True)
ranking_dy.sort_values(by='rank', ascending=False, inplace=True)
ranking_dy.head(10)

"""### Liquidez"""

ranking_liquidez = base_de_dados.loc[:, ['liquidezMediaDiaria']]
ranking_liquidez = ranking_liquidez[ranking_liquidez['liquidezMediaDiaria'] > 0]
ranking_liquidez['rank'] = ranking_liquidez['liquidezMediaDiaria'].rank(ascending=True)
ranking_liquidez.sort_values(by='rank', ascending=False, inplace=True)
ranking_liquidez.head(10)

"""## Aplicando técnicas de análise"""

tem_preco = base_de_dados[(base_de_dados['price'] > 0) & (base_de_dados['maxValue'] > 0)]
pl_positivo = tem_preco[tem_preco['p_L'] > 0]
tickers = list(pl_positivo.index)

dataframes_dict = {
  'ev_bit': ranking_ev_ebit.loc[ranking_ev_ebit.index.isin(tickers)],
  'roic': ranking_roic.loc[ranking_roic.index.isin(tickers)],
  'cagr': ranking_cagr.loc[ranking_cagr.index.isin(tickers)],
  'queda_max': ranking_queda_max.loc[ranking_queda_max.index.isin(tickers)],
  'pl': ranking_pl.loc[ranking_pl.index.isin(tickers)],
  'pvp': ranking_pvp.loc[ranking_pvp.index.isin(tickers)],
  'dvlp': ranking_dvlp.loc[ranking_dvlp.index.isin(tickers)],
  'liqcorrente': ranking_liqcorrente.loc[ranking_liqcorrente.index.isin(tickers)],
  'roe': ranking_roe.loc[ranking_roe.index.isin(tickers)],
  'dy': ranking_dy.loc[ranking_dy.index.isin(tickers)]
}

def gera_avaliacao(keys):
  dataFrames = [dataframes_dict[key] for key in keys]
  joinDataFrames = lambda df1, df2: df1.add(df2, fill_value=0)
  result = functools.reduce(joinDataFrames, dataFrames)
  return result.sort_values(by='rank', ascending=False)

"""### ***Magic Greenblat (EV/EBIT, ROIC)***

"""

result_magic = gera_avaliacao(['ev_bit', 'roic'])
result_magic.head(10)

"""### ***MAGIC Lucros (EV/EBIT, ROIC, CAGR 5 anos)***"""

result_magic_lucros = gera_avaliacao(['ev_bit', 'roic', 'cagr'])
result_magic_lucros.head(10)

"""### ***Baratas (Queda. Max, P/L, P/VP)***"""

result_baratas = gera_avaliacao(['queda_max', 'pl', 'pvp'])
result_baratas.head(10)

"""### ***Solidas (Div. Liquida/Patrimônio, Liq. Corrente, CAGR 5 anos)***"""

result_solidas = gera_avaliacao(['dvlp', 'liqcorrente', 'cagr'])
result_solidas.head(10)

"""### ***Mix (P/L, P/VP, Liq. Corrente,  ROE, CAGR 5 anos)***"""

result_mix = gera_avaliacao(['pl', 'pvp', 'liqcorrente', 'roe', 'cagr'])
result_mix.head(10)

"""### ***DIvidendos (CAGR 5 anos, Dividend Yield)***"""

result_dividendos = gera_avaliacao(['cagr', 'dy'])
result_dividendos.head(10)

"""### ***Grahan (P/L, P/VP, DIvidend Yield)***"""

result_grahan = gera_avaliacao(['pl', 'pvp', 'dy'])
result_grahan.head(10)

"""## **Resultado:**"""

result = {}
limit = 10
tecnicas = [
  ('magic', result_magic.head(limit)),
  ('magic_lucros', result_magic_lucros.head(limit)),
  ('baratas', result_baratas.head(limit)),
  ('solidas', result_solidas.head(limit)),
  ('mix', result_mix.head(limit)),
  ('dividendos', result_dividendos.head(limit)),
  ('grahan', result_grahan.head(limit)),
]

for ticker in tickers:
  result[ticker] = {k: ticker in v.index for k, v in tecnicas}
  result[ticker]['score'] = sum(result[ticker].values())

rkg = pd.DataFrame(result).T
rkg.sort_values(by='score', ascending=False, inplace=True)
rkg.head(20)

"""### 20 empresas selecionadas"""

final_result = base_de_dados.loc[rkg.index].head(20)
final_result['score'] = rkg['score']

print(final_result)

"""### Popular base de dados"""
final_result['ticker'] = final_result.index
final_result.index = np.arange(len(final_result))

engine = create_engine("postgresql://{user}:{pw}@{host}:{port}/{db}"
                       .format(user=os.getenv('DB_USER'),
                               pw=os.getenv('DB_PASSW'),
                               host=os.getenv('DB_HOST'),
                               port=os.getenv('DB_PORT'),
                               db=os.getenv('DB_NAME')))
final_result.to_sql('final_result', con = engine, if_exists = 'replace', chunksize = 1000)

for k in dataframes_dict:
  df = dataframes_dict[k]
  df['ticker'] = df.index
  df.index = np.arange(len(df))
  df.to_sql(k, con = engine, if_exists = 'replace', chunksize = 1000)